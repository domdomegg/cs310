\title{%
  \Huge{\textbf{Interactive Tool for Teaching Hindley-Milner Type Inference through Visualisation}}
  \\
  \Large{Final report\\~\\~\textbf{Adam Jones}\\~Department of Computer Science\\~University of Warwick}
}

\documentclass[a4paper,fleqn,12pt]{article}

\usepackage[]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[UKenglish]{babel}
\usepackage[UKenglish]{isodate}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{chngpage}
\usepackage{calc}
\PassOptionsToPackage{hyphens}{url}
\usepackage{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{fancyhdr}
\usepackage{titletoc}
\usepackage[explicit]{titlesec}
\usepackage{natbib}
\usepackage[dvipsnames]{xcolor}
\usepackage[sc]{mathpazo}
\linespread{1.05} 
\usepackage[T1]{fontenc}
\usepackage{minted}
\usepackage{ragged2e}
\usepackage{adjustbox}

\hypersetup{
	colorlinks=true,
	linkcolor=black,
	urlcolor=black,
	citecolor=black
}

\definecolor{lightgrey}{rgb}{0.95,0.95,0.95}
\setminted{bgcolor=lightgrey}
\setmintedinline{bgcolor=lightgrey,escapeinside=||,mathescape=true}

\let\parencite\citep

\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\renewcommand\baselinestretch{1.2}

\cleanlookdateon

\pagestyle{plain}
\renewcommand{\headrulewidth}{0.0pt}

\makeatletter
\fancypagestyle{plain}{
	\fancyhf{}
	\fancyhead[RE,RO]{\thepage}
	\fancyhead[LE,LO]{\textit{Interactive Tool for Teaching HM Type Inference through Visualisation}}
}
\makeatother

\begin{document}

\makeatletter
\begin{titlepage}

\LARGE \@title \\
\Large \\[1.5cm]

\vfill 

\begin{adjustwidth}{-\oddsidemargin-1in}{-\rightmargin}
  \centering
  \includegraphics[width=\paperwidth]{line.png}
\end{adjustwidth}

\vspace*{-3.5cm}

\end{titlepage}
\makeatother

\pagestyle{plain}




TODO: Abstract
\section{Introduction}\label{id:h.6k9gcmunzldy}
Types are common features of many programming languages. Generally, types are bounds on program constructs (such as variables, expressions and functions) that limit what valid values they may take and how they should be interpreted within the program, however different languages use types differently. Most type systems include primitive data types such as integers, booleans and characters as well as composite types such functions from one type to another and lists of a type.

Type checking is the process by which a language’s compiler or interpreter validates that a program obeys the rules of the language’s type system. When a violation is detected, such as providing a boolean to a function accepting an integer, a type error is raised.

Type checking is primarily used to catch bugs in program code, preventing unexpected behaviour. A simple example of this is function application: functions’ types specify how they can be called which ensure some pre-conditions are met, such as the arguments being of an expected type. This allows function implementers to safely assume the data is of that type, and prevents function users calling the function with invalid arguments.

Type checking can happen either at compile time (static type checking) or runtime (dynamic type checking).

Compile-time type checking prevents many type errors from occurring at runtime. This is particularly useful when code paths may not be well tested or frequently used, as runtime checks only surface type errors when the problematic code is executed. Additionally, knowing types at compile-time allows for better tooling that improves developer productivity. For example, IDEs may use type information to suggest and perform automated refactorings \citep{ref1}, automatically generate documentation \citep{ref2} and autocomplete statements \citep{ref3}.

Compile-time type checking requires the program code to have enough information to validate its type safety. This may be in the form of type annotations or typed variable and function declarations. However, specifying types manually can be time-consuming and potentially difficult as it is additional work for the programmer, and large composite types can be especially difficult to determine and tedious to repeatedly write.

A type inference algorithm for a programming language’s type system can determine types automatically, which improves productivity by allowing programmers to get the best of types without having to explicitly specify them. Because of this, type inference is used in many popular programming languages with expressive type systems including Haskell, Rust and TypeScript.

An understanding of type inference would help computer scientists write cleaner code and debug type errors. However, few universities have core modules on type systems (although they may be touched on in programming curriculums) and there are limited easy-to-understand teaching resources on type inference. Therefore, many computer science graduates will be missing a useful understanding of how type inference actually works.

The goal of this project is develop a system to visualise the type inference process, with the aim of improving undergraduate students’ knowledge about it.

To achieve this, we develop a teaching resource that explains how type inference algorithms work for functional languages. An interactive web application allows students to enter expressions and view the results of a type inference algorithm, along with the steps taken to get to that result. This is particularly useful in the context of modules teaching functional languages such as Haskell which perform similar type inference.
\subsection{Related work}\label{id:h.2mwaav7jkal4}
There have been previous attempts to build visualisation and teaching tools related to type systems.

{\centering \begin{figure}[h!]
  \centering
  \includegraphics[width=0.770\linewidth]{images/image7.png}
  \caption{Screenshot of results from TypeTool, taken from their paper}
\end{figure} \par}

One example is TypeTool by~\cite{ref4}, which visualises type inference through a web application. Users enter an expression in a custom expression language, submit a request to a server and are redirected to a page displaying an initial syntax tree, a final syntax tree and an overall substitution. By allowing users to enter their own expressions, students can explore how the systems work in different cases to gain an intuitive understanding of the concepts.

TypeTool’s authors found in teaching the University of Porto’s functional programming course that the tool was “especially useful for students, because it helps to understand the type systems of the most common typed functional languages” and that “[presenting] the basis of type inference technology [...] significantly improved the way students deal with type errors because they understand the type system.”

However, TypeTool’s parsing and type inference is done server-side so there is a delay between the user entering an expression and seeing the result. While short, a delay reduces the ease-of-use and may discourage users from trying many different expressions. Both delayed feedback and the lack of step-by-step explanations reduce learning quality \citep{ref5}, particularly in the area of rule learning.~\cite{ref6} showed that immediate explanatory feedback is most effective at learning how to apply rules in computer programming. It also lacks step-by-step explanations, and it is unclear whether it supports processing incorrectly-typed expressions.

In addition, the tool is now inaccessible as the server hosting the application is no longer running and the source code has not been published.

Another tool in the area of visualising type systems was developed by~\cite{ref7}. It is a visual functional programming system which shows types during function application for a subset of Standard ML, used to teach first year undergraduate students. However, this did not explicitly show the type inference process and as a desktop application rather than web app it is less accessible to lecturers and students. It also didn’t support key functional language constructs such as function declarations and let bindings, and required significant explanation before using the tool to understand its output.

{\centering \begin{figure}[h!]
  \centering
  \includegraphics[width=0.797\linewidth]{images/image2.png}
  \caption{Screenshot of Yung and Michaelson's tool, taken from their paper}
\end{figure} \par}

NiMo \citep{ref8} is a graphical programming language related to functional data processing which allows users to reason about the flow of data through a program. The types of data and processes can be inspected in NiMoToons, and type inference is performed over the network of components. However, larger expressions can become complicated and be difficult to interpret. While NiMo performs type inference internally it is not a key focus to the end-user, and as such does not explain its steps. Additionally, it is harder to relate back to more commonly used, textual functional languages like Haskell.

{\centering \begin{figure}[h!]
  \centering
  \includegraphics[width=0.960\linewidth]{images/image4.png}
  \caption{A diagram showing the types of some variables in NiMo, taken from their paper}
\end{figure} \par}

\cite{ref9} implemented a successful teaching tool, named TILC, for visualising lambda-calculus parse trees in order to help with teaching lambda-calculus to undergraduate students. They noted that to develop an intuitive understanding, students would benefit from  experimenting with lambda-calculus and that “a tool that deals with all these aspects in a friendly and graphical manner incentivises [experimentation]”. TILC was successful, with the module organisers of ‘programming paradigms’ at the Universitat de Girona having a “good experience of using this tool in the course lectures and as a downloadable tool for students”. The authors suggested extending TILC to show types and type inference would have pedagogical value.

To summarise, types aid the construction of correct programs and type checking can detect issues in programs, either at compile-time or runtime. Type inference is a method often used alongside compile-time type checking to determine types in a program, an understanding of which could benefit computer scientists in writing and debugging programs. Some solutions exist which give students a better idea about types, however they either have significant limitations or do not explicitly cover type inference. In this report, we present an interactive web application for teaching type inference.
\section{Background}\label{id:h.ebjyqi73zdyo}
\subsection{$\lambda$-calculus}\label{id:h.odw4vku9eizz}
A $\lambda$-calculus is a representation of computation. The first $\lambda$-calculus set out by \footnote{church}, often viewed as the canonical $\lambda$-calculus, simply has variables, function abstraction and application.

For this project, we will consider a calculus with five constructs to build expressions from. As a formal grammar:

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.510\linewidth]{images/image6.png}
\end{figure}
    | c constant

TODO: latex-ify the above

For example, consider the expression \mintinline{text}{|($\lambda$x. x) y|}

It has variables \mintinline{text}{|x|} and \mintinline{text}{|y|}. Variables may be bound or free (unbound). Here \mintinline{text}{|x|} is bound as it is a parameter in the function abstraction, and \mintinline{text}{|y|} is free as there is nothing which binds it. This can be thought of in a similar way to how variables in most imperative programming languages have a scope where they are defined or undefined.

The function abstraction mentioned is the \mintinline{text}{|$\lambda$x. x|} part. This defines an anonymous function which given an argument (before the full stop) \mintinline{text}{|x|} simply returns (after the full stop) \mintinline{text}{|x|}, i.e. the identity function. A function to add three to an input might be written \mintinline{text}{|$\lambda$x. x + 3|} (although many of the most fundamental $\lambda$-calculi do not have such explicit notions of addition or numbers).

Functions may be returned by other functions, which enables functions to have the appearance of taking multiple arguments. For example \mintinline{text}{|$\lambda$x. ($\lambda$y. x)|} can be viewed as a function which takes two arguments and returns the first one, even though really it is a function taking one argument which returns a function taking another argument for a result. Here explicit brackets have been given for clarity, but they aren’t necessary. Additionally, sometimes multiple arguments like this are written together, so \mintinline{text}{|$\lambda$x. ($\lambda$y. x)|}, \mintinline{text}{|$\lambda$x. $\lambda$y. x|} and \mintinline{text}{|$\lambda$xy. x|} all mean the same thing.

Finally, the function application is actually applying the function \mintinline{text}{|$\lambda$x. x|} to the argument \mintinline{text}{|y|}. In $\lambda$-calculus evaluation is performed via $\beta$-reductions. In our example this could be done by substituting the argument \mintinline{text}{|y|} for parameter \mintinline{text}{|x|} in the body of the function \mintinline{text}{|x|}, resulting in \mintinline{text}{|y|}:

This expression’s construction can be represented as an abstract syntax tree:

TODO: tree diagram of the expression

In addition to these three constructs, the \mintinline{text}{|let|} construct allows binding a value to a variable in an expression. For example \mintinline{text}{|let x = 3 in x + x|} binds \mintinline{text}{|x|} to the value \mintinline{text}{|3|} in \mintinline{text}{|x + x|}.

A \mintinline{text}{|con|} construct is added to represent literal constants, such as numbers or booleans like \mintinline{text}{|3|} and \mintinline{text}{|True|}.

$\lambda$-calculi have been extensively studied, often using formal inductive definitions. For example, the inductive definition for the set of free variables (\mintinline{text}{|var|}s not bound by function abstraction or let statements) is:
\begin{itemize}
  \item \mintinline{text}{|var|}: $FV(x) = \{ x \}$
  \item \mintinline{text}{|abs|}: $FV(\lambda x. E) = FV(E) - \{ x \}$
  \item \mintinline{text}{|app|}: $FV(E\_1 E\_2) = FV(E\_1) \cup FV(E\_2)$
  \item \mintinline{text}{|let|}: $FV(let x = E\_1 in E\_2) = FV(E\_2) - \{ x \}$
  \item \mintinline{text}{|con|}: $FV(c) = \varnothing$
\end{itemize}
where E is any expression.

TODO: fix latex of above

Given these rules the set of free variables for any combination of these constructs can be determined. This can be demonstrated for our example expression \mintinline{text}{|($\lambda$x. x) y|}, which is shown in a tree structure below. More generally this is an example of how an inductive definition can tell us something about the entire program which is how some type inference algorithms can be viewed.

TODO: tree diagram of the expression with the sets of free variables at each node.

Most real-world environments define a context which binds some variables by default to in-built values. For example Haskell’s GHC primitives and Prelude includes basic variables like \mintinline{text}{|[]|} (the empty list) and \mintinline{text}{|not|} (a function which inverts booleans). These can be considered bound at the top level and removed from the set of free variables there.
\subsection{The simply typed $\lambda$-calculus}\label{id:h.w7vj0r89b86n}
Typed $\lambda$-calculi extend the system with the concept of types.

The simply typed $\lambda$-calculus is one of the simplest typed $\lambda$-calculi, and introduced by~\cite{ref11} is often viewed as the canonical typed $\lambda$-calculus. It has the \mintinline{text}{|var|}, \mintinline{text}{|abs|}, \mintinline{text}{|app|} and \mintinline{text}{|con|} constructs. Types in this system are either base types (often in the literature Greek letters $\alpha$, $\beta$, $\gamma$ are used, but these can be thought of similar to numbers, booleans, characters etc.) or functions between other types (such as \mintinline{text}{|Int -> Bool|}, or \mintinline{text}{|Int -> (Bool -> Bool)|}).

The syntax adds type annotations to \mintinline{text}{|var|}, \mintinline{text}{|abs|} and \mintinline{text}{|con|} constructs, for example ($\lambda$x: Int. odd\textsuperscript{Int -> Bool} x\textsuperscript{Int}) 3\textsuperscript{Int} (although often for simplicity the types of \mintinline{text}{|var|} and \mintinline{text}{|con|} subexpressions, those in superscript, are left out).
\subsection{Hindley-Milner type system}\label{id:h.gsouq2axz3k}
Hindley-Milner (HM) is a typed $\lambda$-calculus which allows for the types of programs to be inferred and no type annotations are required \citep{ref12,ref13}. It extends the simply typed $\lambda$-calculus by adding \mintinline{text}{|let|} bindings and a richer type system that includes \textit{type functions} and \textit{polymorphism}.

Like expressions, types can be considered to be built from \mintinline{text}{|var|} variables and \mintinline{text}{|app|} function applications. Type variables are either base types like \mintinline{text}{|Bool|} and \mintinline{text}{|Int|} or type functions. Type functions can be applied, taking types as parameters to construct composite types.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.467\linewidth]{images/image1.png}
\end{figure}
where C is a set of type functions such as \mintinline{text}{|->|}, \mintinline{text}{|List|} and \mintinline{text}{|Maybe|}.

TODO: latexify the above, replace alpha with tn

For a type to be valid all functions must be fully applied, unlike expressions where the final expression may be a function.  As with expressions, we can again assume a global context that binds the basics variables like \mintinline{text}{|Bool|} and \mintinline{text}{|Int|}. In Hindley’s original paper only \mintinline{text}{|->|} was considered as a type function (i.e. $C = \{ -> \}$), however here we explore several type functions that have been found useful in practice.

The type function we’ve already been using is \mintinline{text}{|->|} (the \textit{function} type function). It takes two types as arguments and represents a function from the first type to the second. A function from \mintinline{text}{|Int|} to \mintinline{text}{|Bool|} is represented by \mintinline{text}{|(->) Bool Int|} in prefix notation, although would more commonly be written infix as \mintinline{text}{|Bool -> Int|}.

The function type function (\mintinline{text}{|->|}) should not be confused with the function type: an expression representing a function has a function type, and that function type is the function type function applied to arguments. For example \mintinline{text}{|$\lambda$x. x + 3|} has a function type \mintinline{text}{|Int -> Int|}, which is the function type function \mintinline{text}{|->|} applied to arguments \mintinline{text}{|Int|} and \mintinline{text}{|Int|}.

The list type function is also very common, which given one type argument represents a list of those types. A list of booleans might be written \mintinline{text}{|List Bool|} or \mintinline{text}{|[] Bool|} in prefix notation, although often the list type is represented by wrapping the type argument in square brackets instead like \mintinline{text}{|[Bool]|}.

\mintinline{text}{|Maybe|} is another type function commonly used in functional languages like Haskell. A \mintinline{text}{|Maybe|} represents the optional presence of something, similar to Java’s \mintinline{text}{|Optional|} and C++’s \mintinline{text}{|std::optional|}. Applied to a boolean type this may be written \mintinline{text}{|Maybe Bool|}, representing a wrapper around nothing or a boolean. In Java this would be represented with a generic as \mintinline{text}{|Optional<Boolean>|} and in C++ as \mintinline{text}{|std::optional<bool>|}.

A similar common type function is \mintinline{text}{|Either|}, which takes two type arguments and represents a wrapper around either one of the types. For example, an either for a boolean or integer is written \mintinline{text}{|Either Bool Int|}.

Finally, tuples represent a defined-length sequence of elements of specific types. Tuple constructors are a set of type functions representing a cross product of their type arguments, named \mintinline{text}{|,|}, \mintinline{text}{|,,|}, \mintinline{text}{|,,,|} and so on for different element lengths. A 3-tuple holding a boolean, integer and integer can technically be written in prefix notation as \mintinline{text}{|(,,) Bool Int Int|} but instead generally tuples borrow mathematical syntax with parentheses and commas like \mintinline{text}{|(Bool, Int, Int)|}.

The set of types made from \mintinline{text}{|var\_t|} and \mintinline{text}{|app\_t|} are known as monotypes. For example, \mintinline{text}{|Bool|}, \mintinline{text}{|Int|}, \mintinline{text}{|Bool -> Int|}, and \mintinline{text}{|Bool -> [(Bool, Int -> Maybe Bool)]|} are all monotypes.

Adding zero or more for-all quantified type variables to monotypes forms polymorphic types or polytypes (called principal type schemes by Hindley). This can be thought of as the \mintinline{text}{|abs|} equivalent for types, written as \mintinline{text}{|\forall a. \rho|} where \mintinline{text}{|\rho|} is a polytype. This definition makes monotypes a special case of polytypes: monotypes are polytypes with zero for-all qualified type variables. By convention, we use $t0, t1, t2, \dots$ for free type variables, and $a, b, c, \dots$ for for-all quantified type variables.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.290\linewidth]{images/image8.png}
\end{figure}

TODO: latexify the above, but use rho instead of sigma and a instead of alpha

Polytypes allow for parametric polymorphism, where a type may be parameterized by a for-all bound quantifier. This allows functions to accept different types as long as they meet certain constraints. For example the \mintinline{text}{|length|} function is polymorphic: it has the polytype \mintinline{text}{|\forall a. [a] -> Int|}, which accepts a list of any type and returns its length as an integer. It accepts different types such as \mintinline{text}{|[Bool]|} and \mintinline{text}{|[Int]|} as both of these meet the constraint of being a list.

Correctly inferring polymorphic types can be difficult, and in fact~\cite{ref14} proved that doing so for System F, a type system similar to Hindley-Milner with fewer typing rule constraints, is undecidable. To prevent undecidability, HM avoids overusing polytypes, using only monotypes for \mintinline{text}{|var|}, \mintinline{text}{|con|}, \mintinline{text}{|app|} and \mintinline{text}{|abs|} expressions.

To allow for some polymorphism, \mintinline{text}{|let|} expressions’ parameters are polymorphic in the \mintinline{text}{|let|} body. The process by which the monomorphic parameter type is turned into a polymorphic one is known as generalisation. The overall type of \mintinline{text}{|let|} expressions themselves are not generalised.

This is the difference between:
\begin{itemize}
  \item \mintinline{text}{|let i = (\lambda x -> x) in (i 3, i True)|} type-checks, as i is generalised to the polytype \mintinline{text}{|\forall a. a -> a|} within the body \mintinline{text}{|(i 3, i True)|} so can be applied to both an \mintinline{text}{|Int|} and \mintinline{text}{|Bool|}
  \item \mintinline{text}{|(\lambda i -> (i 3, i True)) (|}$\lambda$x. x)\mintinline{text}{| does not type-check as the function abstraction |}($\lambda$x. x)\mintinline{text}{| has the monotype |}t0 -> t0\mintinline{text}{|, and |}t0\mintinline{text}{| must take only one type in both tuple parts - it cannot be both an |}Int\mintinline{text}{| and a |}Bool\mintinline{text}{|.|}
\end{itemize}

Hindley-Milner is the basis for the type system of Standard ML \citep{ref15} (which OCaml and F\# are related to) and was the basis of the type system in Haskell \citep{ref16}. It has influenced the development of Rust and Swift, and more generally type inference is present in many more languages including Java, JavaScript and C++.

Haskell has since been extended with type-class constraints \citep{ref17}, functional dependencies \citep{ref18}, and generalised algebraic data types (GADTs) \citep{ref19}. Haskell’s inference engine was moved onto a new engine, OutsideIn(X), when GHC 7.2 was released November 2011 after~\cite{ref20} proposed a solution to the issues with Hindley-Milner’s poor performance on large programs and difficulty inferring expressions without principal types that arise with type-class constraints and GADTs. In doing this, Haskell stopped automatically generalising variables bound by \mintinline{text}{|let|} expressions after~\cite{ref21} argued that generalising \mintinline{text}{|let|} bindings is complex in type inference engines other than HM and the feature was rarely used in practice, with the change only affecting 0.13\% lines of the GHC core libraries. This change does however take it further away from performing HM-like type inference.

Rust’s compiler, rustc, did at one time use a variant of HM for type inference. However,~\cite{ref22} proposed a new scheme which was later implemented to simplify how the compiler reasoned about types. Similarly to Haskell’s move to OutsideIn(X), the new type inference reduces flexibility in some edge cases, although practically this is rare. Both rustc and Rust’s core libraries compiled under the new type inference scheme without changes. Later on,~\cite{ref23} developed chalk, a library designed to be used in rustc to help implement Rust’s generics. This library makes heavy use of unification, a key component of many HM type inference algorithms.

Apple’s Swift heavily uses type inference. It is implemented using a “constraint-based type checker that is reminiscent of the classical Hindley-Milner type inference algorithm” \citep{ref24}. Like other languages it extends HM with additional language features, such as more expressive polymorphic types with additional constraints. To adapt HM to a procedural language, and for improved performance and better error messages, Swift limits type inference to individual statements rather than entire programs.

In addition to their own inference engines, many languages allow the programmer to add more type information through explicit type annotations or casting. This is particularly helpful where the programmer knows more than the type inference algorithm about the limits on how a part of a program will be used.

Java allows casting objects and TypeScript has its \mintinline{text}{|as|} type assertion operator. Programmers can use these sparingly (and often in combination with \mintinline{text}{|instanceof|} and \mintinline{text}{|typeof|} operators respectively) as an escape hatch to work around the type inference algorithm’s limitations. In these situations statements may not be able to be type checked at compile-time so instead runtime checks are performed to maintain type safety.

Java allows casting an object to a subclass \citep{ref25}. Runtime checks are performed, which throw a \mintinline{text}{|ClassCastException|} in case the object is not actually an instance of the subclass.

\begin{minted}[breaklines]{java}
// Dog and Cat extend Animal

Animal c1 = new Dog();
Dog s1 = (Dog) c1; // okay

Animal c2 = new Cat();
Dog s2 = (Dog) c2; // throws ClassCastException at runtime
\end{minted}

TypeScript allows for casting compatible objects with its \mintinline{text}{|as|} operator, or overriding the compile-time type checking completely with a \mintinline{text}{|@ts-ignore|} comment. The following shows that some type-safe code is rejected by the TypeScript type checker, but with several possible workarounds.

\begin{minted}[breaklines]{typescript}
const a = Math.random() < 0.5 ? 'cs310' : 310; // has type "cs310" | 310
const b = a + a; // throws a type error, but b could have type "cs310cs310" | 620

const c = a == 'cs141' ? a + a : a + a; // okay, has type number | string
const d = a as any + a; // okay, has type any
const e = a as any + a as 'cs310cs310' | 620 // okay, has type "cs310cs310" | 620
// @ts-ignore
const f: 'cs310cs310' | 620 = a + a; // okay, has type "cs310cs310" | 620
\end{minted}

While real-world languages don’t work exactly like HM, for the purposes of the teaching tool HM gives a good representation of how type inference works to students. HM avoids being too complex to understand, and is still related to how languages commonly used in practice perform type inference.
\subsection{Hindley-Milner type inference}\label{id:h.admfqf7bhkct}
Various algorithms are available to infer types in Hindley-Milner such as Algorithm W by~\cite{ref26} and Algorithm M by~\cite{ref27}. Algorithm W takes a bottom-up approach, attempting to infer the types of subexpressions up the abstract syntax tree, while Algorithm M takes a top-down approach, inferring types down the tree. Algorithm W’ is a minor extension to Algorithm W, by~\cite{ref28} which can improve the quality of type errors raised.

Substitutions are a key concept from logic used by the algorithms. These are maps from variables to terms. When applied to an expression, the variables are substituted with their corresponding terms. In the case of type inference, the variables are type variables, the terms are monotypes and expressions are types.

TODO: fix this latex

Substitutions are represented with curly braces, with each entry separated by a comma and the variables and terms separated with an arrow. For example, $\{ t0 \mapsto t1, t2 \mapsto (Int, Bool) \}$ would replace $t0$ with $t1$, and replace $t2$ with $(Int, Bool)$. Applied to the type $t0 -> t1 -> t2$ results in $t1 -> t1 -> (Int, Bool)$.

When applying substitutions replacements are performed simultaneously, meaning each variable in the expression may be mapped at most once. For example the substitution $\sigma = \{ t0 \mapsto t1, t1 \mapsto t2 \}$ applied once to the expression $t0$ ($\sigma(t0)$) results in $t1$, not $t2$. Applying the substitution twice, $\sigma(\sigma(t0))$ would result in \mintinline{text}{|t2|}.

Any number of substitutions may be applied to expressions. For example, given $\sigma\_1 = \{ t0 \mapsto t2, t1 \mapsto t3 \}$ and $\sigma\_2 = \{ t0 \mapsto t1 \}$, we may apply both to an expression $t0$. Note that this is not commutative, $\sigma\_1(\sigma\_2(t0)) = t3$ while $\sigma\_2(\sigma\_1(t0)) = t2$.

Substitutions may be combined to have the same effect as applying them in order. For example, with $\sigma\_1 = \{ t0 \mapsto t2, t1 \mapsto t3 \}$ and $\sigma\_2 = \{ t0 \mapsto t1 \}$ again, $combine(\sigma\_1, \sigma\_2) = \{ t0 \mapsto t3, t1 \mapsto t3 \}$. As application is not commutative, the order substitutions are combined in matters, i.e. $combine(\sigma\_1, \sigma\_2)$ does not necessarily equal $combine(\sigma\_2, \sigma\_1)$. Combining substitutions is however associative, as $combine(\sigma\_1, combine(\sigma\_2, \sigma\_3))(E) = \sigma\_1(\sigma\_2(\sigma\_3(E))) = combine(combine(\sigma\_1, \sigma\_2), \sigma\_3)(E)$

A substitution is said to unify two expressions if when applied to both it results in equal expressions. For example, $\{ t0 \mapsto Int, t1 \mapsto Bool \}$ unifies $(t0, Bool)$ and $(Int, t1)$, as when the substitution is applied to either expression the result is $(Int, Bool)$.

Unification is the process of finding unifying substitutions given two expressions, or reporting no such substitution exists.~\cite{ref29} presents a simple algorithm for unification, and~\cite{ref30,ref31} set out linear time unification algorithms.

In the type inference algorithms W, W’ and M, unification is applied to pairs of monotypes. This results in substitutions which effectively combine the various type constraints giving us a final type.

For example, take an expression satisfying two type constraints: it matches the monotype $[Bool] -> t0$ and it matches with the monotype $[t1] -> t1$. These constraints might arise in evaluating the type of \mintinline{text}{|head [True]|}. The first constraint is from knowing \mintinline{text}{|[True]|} is a $[Bool]$ so the function should accept a $[Bool]$. The second constraint is based on the known definition of \mintinline{text}{|head|} in the global context. Unification can find the unifying substitution $\{ t0 \mapsto Bool, t1 \mapsto Bool \}$, giving the overall type $[Bool] -> Bool$. We can then see the resultant type of \mintinline{text}{|head [True]|} is $Bool$.

If at any point unification is not possible, the type constraints must be incompatible and so a type error is raised. For example, there is no unifying substitution for $Int -> t0$ and $Bool -> t1$ as one is a function accepting an $Int$ and the other accepts a $Bool$.

For practical purposes, in type inference algorithms we require unifying substitutions to be finite as infinite types are difficult to represent and reason about. For example \mintinline{text}{|x|} in \mintinline{text}{|$\lambda$x. x x|} needs to be a function that accepts itself. Initially assuming \mintinline{text}{|x|} has type $t0 -> t1$ and knowing it should accept itself, it also has type $(t0 -> t1) -> t1$. It also must accept that, so has type $((t0 -> t1) -> t1) -> t1$, $(((t0 -> t1) -> t1) -> t1) -> t1$, and so on. This is an infinite type and is not allowed by HM. Note that this does not exclude functions from HM which do accept themselves, such as the identity function \mintinline{text}{|id|}, as long as they have finite types.

Detecting infinite types in unification is done by checking whether the types are not equal and one of the types occurs in another. This is known as the occurs check. In the previous example \mintinline{text}{|$\lambda$x. x x|} we might try to unify $t0 -> t1$ with $t0$. $t0$ occurs in $t0 -> t1$ so there is no finite unifying substitution (an infinite unifying substitution is $\{ t0 \mapsto ((((t0 -> t1) -> t1) -> infinite t1s…) -> t1) \}$). The occurs check failing necessarily means we have an infinite type: the type contains itself.

Inferring types generally is done in a global typing context, often with built-in functions and their types pre-defined. Haskell’s Prelude and JavaScript’s global objects are practical examples of these. Additionally, when in the bodies of constructs that bind variables like \mintinline{text}{|abs|} and \mintinline{text}{|let|} a local context may be used to store these and parent bindings. Typing contexts can be seen as maps from variable names to their corresponding types, and are represented with the symbol $\Gamma$.

Some types are considered more general than others. A type $\rho\_a$ is more general than a type $\rho\_b$ if there exists a substitution from $\rho\_a$ to $\rho\_b$ whose variables are for-all quantified in $\rho\_a$. This is denoted by $\sqsubseteq$, for example $\forall a. a -> a$ is more general than $Int -> Int$ by the substitution $\{ a \mapsto Int \}$, written $\forall a. a -> a \sqsubseteq Int -> Int$. For a type to be less general than another, as at least one for-all quantified variable must be substituted away it must have at least one fewer quantified variables.

An expression with a type more general than another can be considered to have the less general type. The process of giving an expression a less general type is known as instantiation of a type. For example, the type of \mintinline{text}{|id|}, $forall a. a -> a$, can be instantiated as $Int -> Int$.

The ‘opposite’ to instantiation is generalisation, where an expression with a certain type can be considered to have a more general type, adding a for-all quantification of a variable. This is allowed where the type variable is not free in any of the types in the context. For example, given a type $t0 -> t1 -> t2 -> t3$ and a context $\{ x : t1, y : [t2] -> Int, z: forall t3. t3 \}$ we may generalise to $\forall t0 \forall t3. t0 -> t1 -> t2 -> t3$. $t0$ is not in any of the types in the context, and $t3$ is only found bound as a for-all quantified variable. Therefore both of these may be for-all quantified. Both $t1$ and $t2$ are free in the context, so may not be generalised. (Note we’re disregarding our convention of using $a, b, c, \dots$ for for-all quantified variables here, to be strict to the typing rules. Renaming the type variables with $\alpha$-conversions could be done after generalisation to maintain the type variable naming conventions.)

Our five key syntax rules plus instatitation and generalisation give us nine typing rules. Many presentations of Hindley-Milner do not include literal constants in their syntax, or do not explicitly type them given their triviality. Here we give them for completeness.

 \begin{figure}[h!]
  \centering
  \includegraphics[width=0.505\linewidth]{images/image5.png}
\end{figure}

---------- [Const\_i]
c\_i : Int

-------------- [Const\_c]
c\_c : Char

-------------- [Const\_b]
c\_b : Bool

TODO: latexify the above, replacing sigma with rho

TODO: what is an AST?

TODO: how does algorithm W work?

TOOD: how does algorithm W’ work?

TODO: how does algorithm M work?

These type inference algorithms do have limitations. They all sometimes produce poor type error messages; Algorithm W often detects errors late, highlighting too large of a subexpression to be useful and Algorithm M often detects too specific of a term without context as to what original definition it violates. Algorithm W has the left-to-right bias which Algorithm W’ attempts to correct for, however this can sometimes exacerbate the problem with highlighting large subexpressions. Poor error messages make it difficult for the programmer to understand how to fix the problem.

To improve error messaging, hybrid or constraint-based algorithms along with heuristics are often used in practice to provide more informative error messages. Reducing the size of the amount inferred at once can help make errors more precise. For example, Apple’s Swift uses a bi-directional type inference algorithm on single statements \citep{ref32}.

Additionally, despite not being required in all languages, explicit type annotations are often used to help identify errors earlier at locations which are easier to interpret \citep{ref33}. This is especially common for function definitions or program entry points. This also effectively splits up the program into smaller parts which can be inferred against separately, improving performance and making type errors more precise. In some cases, type inference algorithms struggle with (directly or indirectly) recursively defined functions and type annotations can help define these types. Finally, changing a rigidly-typed interface also highlights potential breaking changes to libraries or helper functions. In this way type annotations act as documentation to future programmers using the code. Manually specified, more specific types may be an improvement over automatically inferred types as sometimes the most general type as worked out by a type inference algorithm may not clearly convey the intent of the programmer.

\underline{\href{https://aaltodoc.aalto.fi/bitstream/handle/123456789/42719/master\_Mikkonen\_Juuso\_2020.pdf}{https://aaltodoc.aalto.fi/bitstream/handle/123456789/42719/master\_Mikkonen\_Juuso\_2020.pdf}}
Talks about statically typed languages in JavaScript-land. Mentions things like TypeScript don’t use HM because JS has a lot of structural typing (i.e. if objects have the right properties it’s fine to call methods that depend on that interface) and subtyping.

\underline{\href{https://research.cs.queensu.ca/home/jana/papers/bidir/Dunfield13\_bidir.pdf}{https://research.cs.queensu.ca/home/jana/papers/bidir/Dunfield13\_bidir.pdf}}
I seem to have come across this paper quite a few times. I still don’t really understand it, but it seems important.

\underline{\href{https://www.sigmacomputing.com/blog/writing-a-parser-combinator-from-scratch-in-typescript/}{https://www.sigmacomputing.com/blog/writing-a-parser-combinator-from-scratch-in-typescript/}}
Parser in TypeScript

\underline{\href{https://tomassetti.me/parsing-in-javascript/}{https://tomassetti.me/parsing-in-javascript/}}
Parsing in JavaScript - lots of library recommendations (see Parjs and Jison)

\underline{\href{http://reasonableapproximation.net/2019/05/05/hindley-milner.html}{http://reasonableapproximation.net/2019/05/05/hindley-milner.html}}
A reckless introduction to Hindley-Milner type inference

\underline{\href{https://en.wikipedia.org/wiki/Types\_and\_Programming\_Languages}{https://en.wikipedia.org/wiki/Types\_and\_Programming\_Languages}}
Book recommended by mbg

\underline{\href{https://homepages.inf.ed.ac.uk/wadler/papers/papers-we-love/milner-type-polymorphism.pdf}{https://homepages.inf.ed.ac.uk/wadler/papers/papers-we-love/milner-type-polymorphism.pdf}}
Original algorithm W paper

\underline{\href{https://www.dcs.warwick.ac.uk/michael\_gale/publications/wsiw.pdf}{https://www.dcs.warwick.ac.uk/michael\_gale/publications/wsiw.pdf}}
Michael’s what should I wear paper

\underline{\href{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.7733\&rep=rep1\&type=pdf}{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.7733\&rep=rep1\&type=pdf}}
\underline{\href{https://gist.github.com/paf31/a49a54d7ea5ede43422f}{https://gist.github.com/paf31/a49a54d7ea5ede43422f}}
Implementing algorithm W in Haskell

\underline{\href{https://codeburst.io/https-chidume-nnamdi-com-npm-module-in-typescript-12b3b22f0724}{https://codeburst.io/https-chidume-nnamdi-com-npm-module-in-typescript-12b3b22f0724}}
Typescript library template

\underline{\href{https://www.researchgate.net/profile/Jurriaan\_Hage/publication/221241370\_Scripting\_the\_Type\_Inference\_Process/links/02e7e51a37f9233c65000000.pdf}{https://www.researchgate.net/profile/Jurriaan\_Hage/publication/221241370\_Scripting\_the\_Type\_Inference\_Process/links/02e7e51a37f9233c65000000.pdf}}
Improving type error messages

\underline{\href{https://dspace.library.uu.nl/bitstream/handle/1874/7297/full.pdf?sequence=8}{https://dspace.library.uu.nl/bitstream/handle/1874/7297/full.pdf?sequence=8}}
Top quality type error messages

\underline{\href{https://manu.sridharan.net/files/mycroft-preprint.pdf}{https://manu.sridharan.net/files/mycroft-preprint.pdf}}
A Practical Framework for Type Inference Error Explanation

\underline{\href{https://theory.stanford.edu/\textasciitilde aiken/publications/trs/FLProject.pdf}{https://theory.stanford.edu/\textasciitilde aiken/publications/trs/FLProject.pdf}}
Designing a FP language

\underline{\href{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.5050\&rep=rep1\&type=pdf}{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.5050\&rep=rep1\&type=pdf}}
PhD thesis which talks about hindley milner and type inference a lot

\underline{\href{http://www.reflection.uniovi.es/ortin/publications/visual-2014.pdf}{http://www.reflection.uniovi.es/ortin/publications/visual-2014.pdf}}
Hybrid dynamically and statically typed languages

\underline{\href{http://lucacardelli.name/papers/typesystems.pdf}{http://lucacardelli.name/papers/typesystems.pdf}}
Paper that introduces the basics of type systems and types n’ stuff

\underline{\href{https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.4267\&rep=rep1\&type=pdf}{https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.4267\&rep=rep1\&type=pdf}}
Algorithm W’, the symmetric unification one

\begin{figure}[h!]
  \centering
  \includegraphics[width=1.000\linewidth]{images/image3.jpg}
  \caption{Screenshot from mbg presentation on structure}
\end{figure}

\section{Design}\label{id:h.7ggvdxb04tzm}
- different ui mockups
- different structures
- different libraries
\section{Implementation}\label{id:h.igepudpadp49}
Developed gdoc2latex

Set up CI system to build latex docs

Tried using Docker to run latex compilation step in GitHub actions, but found it was significantly slower (2 mins vs 45 seconds) than installing texlive-latex-extra and texlive-bibtex-extra on the runner directly.

Implemented algorithm W in a mix of class-based and functions, then reimplemented to be just functions.

Added custom test matcher

How the step logging works

How does the web app work, performance analysis and considerations

Analytics

Adding algorithm M and W’
\section{Evaluation}\label{id:h.e6letww4nhn0}
Maybe also analyse performance?

Compare to existing available libraries?

\subsection{User testing}\label{id:h.bsy9mpun8nk3}
Lay out the aims of user testing, i.e.: (goals increasing in ‘scope’)
- software is accessible and usable
- the results can be understood
- it improves students’ understanding of types and type inference

How the survey was constructed and how that relates to aims

How the survey was distributed and incentivised

How analytics data was collected and how that relates to aims

How participants privacy was protected
\subsubsection{Survey}\label{id:h.yqiowsgjmohq}
Questions:
- Try entering: map odd []. Try to understand the steps. What is the unifying substitution performed in step 3?
- Try entering: not 3. Try to understand the steps. What is the problem found?

TODO: Expand on what options were available for these questions and why

These questions were to verify users were able to access, use and interpret the results of the tool. This helps test the hypothesis that the software was accessible and usable, and that results could be understood.

The first had 91\% of respondents select the correct answer. 2 respondents chose the type distractor, and 1 respondent entered a different substitution. 1 respondent did not understand the output enough.

The second had 100\% of respondents select the correct answer.

In both questions, no respondents selected that they could not access or use the software, and the high correct response rate for both questions support hypotheses 1 and 2.

Questions:
- What is really helpful about this tool?
- What could be improved in this tool?

These questions were to better understand qualitatively what helped students understand type inference, so the tool could be improved. Determining what is most helpful about the tool allows focusing on those parts, while asking what could be improved highlights areas to be changed.

Positive themes found were:
- 2x Function application was explained well, which also helped explain curried functions
- 23x Steps are clear / easy-to-understand
- 15x Steps are well-presented / well-visualised
- 8x Tool explains why invalid expressions are invalid
- 8x Showing substitutions helped explain unification
- Learnt how let syntax worked
- 9x Liked visual design / colour scheme
- Tool helpful for more complex examples
- Liked being able to try different things, felt it was more effective than slides/books
- Examples were helpful
- 13x helped me understand unification
- 11x helped me understand type inference
- 4x helped me understand Haskell
- Application is very fast

Improvement themes found were:
- 2x Information on homepage could be made more obvious
- Contact details on the website could help report bugs, give feedback
- Automatically suggesting typo corrections e.g. ‘Fals’ to ‘False’
- On mobile changing the input expression should not cause the screen to move
- Adding functor and applicative support
- Adding support for list comprehensions
- 5x Adding more general information on the HM type system and the HM algorithm
- 4x Using arrows to navigate through steps rather than scrolling
- 3x Function application step could be made clearer
- 2x Fix typo ‘instatiate’ -> ‘instantiate’
- Support infix expressions
- Adding a quiz mode
- 3x Improve wording of function application step
- 2x Adding support for declaring custom types
- Swapping order of AST and explaining content
- 2x Making it clearer the expression box was a text input
- Want input expression to be visible when scrolled down the page
- 1x Disliked colour scheme
- Use more mathematical notation
- 2x Add animation
- Add dark theme
\subsubsection{Analytics}\label{id:h.67g05flyfv0z}

\section{Conclusions and Further Work}\label{id:h.fc67ipatea73}

\section{Ethics}\label{id:h.i0n8c6hqdr6j}

\section{Acknowledgements}\label{id:h.xqaef57orpsv}
This document was typeset using a derivative of the CS310 starter pack\footnote{\href{https://github.com/mbg/cs310}{https://github.com/mbg/cs310}} by Michael Gale, licensed under CC BY 4.0.




































\bibliography{index}

\bibliographystyle{./plainnat}

\end{document}